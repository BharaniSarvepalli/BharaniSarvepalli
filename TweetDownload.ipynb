{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ef5b7213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5xMQc5YE0pxDI4dBQtF4Dq9YuCkyXjBxpFakep9pNtJvW\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import configparser\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "#readconfigs\n",
    "config = configparser.ConfigParser()\n",
    "config.read('c://Users/j1007736/Downloads/config.ini')\n",
    "api_key = config['twitter']['api_key']\n",
    "api_key_secret = config['twitter']['api_key_secret']\n",
    "access_token = config['twitter']['access_token']\n",
    "access_token_secret = config['twitter']['access_token_secret']\n",
    "# authentication\n",
    "auth = tweepy.OAuthHandler(api_key,api_key_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "print(access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "217fbb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a dictionary which contains the companies that we will extract data for, with the key being the full name of the compant and the value being the Yahoo Finance abveriation\n",
    "dict_keyword = ['NIFTY','#NIFTY','#TCS','TATA CONSULTANCY SERVICES','TATA CHEMICALS','TATACHEM','#TATACHEM','#TATACHEMICALS']\n",
    "\n",
    "#TODO\n",
    "# SHOULD BE REPLACED WITH A CONFIG or KEY VALUE PAIR TO DYNAMICALLY CHANGE THE KEYWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dbccbac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dict_keyword:\n",
    "    keywords = x\n",
    "    limit = 5000\n",
    "    likes = []\n",
    "    time = []\n",
    "    user_name = []\n",
    "    user_location = []\n",
    "    user_verified = []\n",
    "    tweets = []\n",
    "    for i in tweepy.Cursor(api.search_tweets,q=keywords,lang=\"en\",count=100,tweet_mode='extended').items(limit):\n",
    "        tweets.append(i.full_text)\n",
    "        likes.append(i.favorite_count)\n",
    "        time.append(i.created_at)\n",
    "        df = pd.DataFrame({'tweets':tweets,'likes':likes,'time':time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d33084b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the text\n",
    "def cleanTxt(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','',text) #Remove @mentions\n",
    "    text = re.sub(r'#','',text) #Removing the '#' symbol\n",
    "    text = re.sub(r'RT[\\s]+','',text) #Removing RT\n",
    "    text = re.sub(r'RT+','',text) #Removing RT\n",
    "    text = re.sub(r'https?:\\/\\/\\s+','',text) #remove the hyper link \n",
    "    return text\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def remove_Stopwords(txt_tokenized):\n",
    "    txt_clean = [word for word in txt_tokenized if word not in stopwords]\n",
    "    return txt_clean\n",
    "\n",
    "#df['tweet_clean'] = df['tweets'].apply(cleanTxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a74ddb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_clean'] = df['tweets'].apply(cleanTxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d2fe1955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C://Users/j1007736/downloads/20220503160223.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "fpath = \"C://Users/j1007736/downloads/\"\n",
    "now = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "fname = fpath+now+\".csv\"\n",
    "print(fname)\n",
    "df.to_csv(fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
